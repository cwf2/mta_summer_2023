{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f148b54",
   "metadata": {},
   "source": [
    "# Preliminaries\n",
    "\n",
    "## Import statements\n",
    "\n",
    "This gives us access to code that isn't part of base Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d496fb0",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "Here we load the feature table calculated in Notebook 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9423c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature table\n",
    "csv_file = os.path.join('data', 'features_by_line.csv')\n",
    "feat_count_line = pd.read_csv(csv_file)\n",
    "\n",
    "# convert the line_ids to Categorical values\n",
    "feat_count_line['line_id'] = pd.Categorical(\n",
    "    values = feat_count_line['line_id'], \n",
    "    categories = feat_count_line['line_id'].unique(), \n",
    "    ordered = True,\n",
    ")\n",
    "\n",
    "# make line_ids the table index\n",
    "feat_count_line = feat_count_line.set_index('line_id')\n",
    "\n",
    "# show the table\n",
    "display(feat_count_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7544aa",
   "metadata": {},
   "source": [
    "# Sampling \n",
    "\n",
    "Now that we have a line-based feature table, the next step is to create a series of larger samples using a **sliding window**. When we're done, we'll have samples of a fixed number of lines that overlap with each other at the edges.\n",
    "\n",
    "## Fixed-size samples\n",
    "\n",
    "To start with, we'll forget about the overlap and just practice cutting the table into samples of a fixed number of lines. Let's create a variable called `size` that stores the size of the window in lines. Let's say we start with something small, like `5`, so we can easily see the effects.\n",
    "\n",
    "Now we want to break up the line-based table into groups of `size` consecutive rows at a time. We need to label each line with a **sample ID** that we can group by. For eample, if `size` is 5, we want to generate something that looks like\n",
    "```\n",
    "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ...]\n",
    "```\n",
    "\n",
    "i.e., something that repeats `size` times in a row and then increments. Then we could feed this into `groupby()` to chunk the line-based table.\n",
    "\n",
    "## Sidebar: floor division\n",
    "\n",
    "One easy way to generate exactly this kind of sequence is with Python's **floor division** operator, `//`. Floor division, also called \"integer division,\" is like regular division except that it drops the decimal part of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efbd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 10\n",
    "b = 3\n",
    "\n",
    "# regular division\n",
    "print(f'{a}/{b} =', a/b)\n",
    "\n",
    "# floor division\n",
    "print(f'{a}//{b} =', a//b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72535c4",
   "metadata": {},
   "source": [
    "Watch what happens if we run through a sequence of dividends with a constant divisor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e141a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_a = 10\n",
    "b = 3\n",
    "\n",
    "pd.DataFrame({\n",
    "    'a': a,\n",
    "    'b': b,\n",
    "    f'a//b': a//b,\n",
    "} for a in range(max_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6daa9",
   "metadata": {},
   "source": [
    "## Generating sample IDs from line IDs\n",
    "\n",
    "This is just the behaviour we're looking for. Now all we need is a constantly increasing serial number for each line, and we can do floor division by `size` to produce our sample id.  Luckily, the Categorial data type that we used for our **line_id** column can convert the category labels to integers (that's how it remembers their sort order).\n",
    "\n",
    "Here we create a set of line-based labels that convert the line urns to serial integers and then to sample ids based on window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4f1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "\n",
    "line_labels = pd.DataFrame(dict(\n",
    "    line_urn = feat_count_line.index,\n",
    "    line_serial = feat_count_line.index.codes,\n",
    "    sample_id = feat_count_line.index.codes // size * size,\n",
    "))\n",
    "display(line_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618721a4",
   "metadata": {},
   "source": [
    "## Collect line-based feature counts by sample ID\n",
    "\n",
    "Now that we can generate a set of sample IDs, we can use `groupby()` to gather our line-based feature counts into counts over `size`-line samples.\n",
    "\n",
    "In order to avoid calculating a lot of feature counts I don't really need, I'm going to identify some features of interest and select just a subset of the columns in the feature table *before* I do the `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9e2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features of interest\n",
    "features = ['pos_ADJ', 'pos_ADV', 'person_2', 'person_3']\n",
    "\n",
    "# group by sample id\n",
    "feat_count_sample = feat_count_line[features].groupby(line_labels.sample_id.values).agg('sum')\n",
    "\n",
    "# inspect results\n",
    "display(feat_count_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5cc3d",
   "metadata": {},
   "source": [
    "## Index samples by line ID\n",
    "\n",
    "This is looking good. The table index (row labels) is the **sample_id** column from the line-based table. As we saw above, it corresponds to the serial number of the first line in the sample. I'm going to change this to the **line_id** of the first line in the sample, just to make it easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-index samples based on line id\n",
    "feat_count_sample = feat_count_sample.set_index(\n",
    "    line_labels['line_urn'].groupby(line_labels['sample_id']).agg('first')\n",
    ")\n",
    "\n",
    "# inspect results\n",
    "display(feat_count_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395bb55",
   "metadata": {},
   "source": [
    "## Inspect the shape of the resulting samples\n",
    "\n",
    "Depending on the size of the window and where it falls, some samples may not have the full complement of lines. At the same time, different lines have different numbers of tokens, and I'm not sure how that will affect the number of tokens per sample.\n",
    "\n",
    "Just to keep my eye on variance in sample size, then, I'm going to calculate both the number of lines and the number of tokens in each sample. We can use this to cull outliers if we need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = feat_count_line.groupby(line_labels.sample_id.values).agg(\n",
    "    lines = ('lemma_ALL', 'count'),\n",
    "    tokens = ('lemma_ALL', 'sum'),\n",
    ").set_index(\n",
    "    line_labels['line_urn'].groupby(line_labels['sample_id']).agg('first')\n",
    ")\n",
    "display(sample_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a386fd",
   "metadata": {},
   "source": [
    "## Moving the sliding window\n",
    "\n",
    "Using this method, we can theoretically chunk our lines into samples of any size we want. But the other piece of the sampling process is moving the window, so that we have samples that start on any given line. Alongside the window **size**, we're going to introduce a new variable, the window **offset**. This is a number less than `size` that adjusts where the first window is placed relative to the first line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb710f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "offset = 1\n",
    "\n",
    "line_labels = pd.DataFrame(dict(\n",
    "    line_urn = feat_count_line.index,\n",
    "    line_serial = feat_count_line.index.codes,\n",
    "    sample_id = (feat_count_line.index.codes - offset) // size * size + offset,\n",
    "))\n",
    "display(line_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb92e8b",
   "metadata": {},
   "source": [
    "### ðŸ¤” What's different here?\n",
    "\n",
    "- At least one of the samples has a negative id: does that make sense?\n",
    "- The first non-negative sample id is `1` instead of `0`\n",
    "- The first line is in a sample all by itself\n",
    "- Sample IDs change on lines ending with `1` and `6` now, not `0` and `5`\n",
    "\n",
    "## Calculate info on the new samples\n",
    "\n",
    "Let's redo our line and token counts for the new sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc22832",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = feat_count_line.groupby(line_labels.sample_id.values).agg(\n",
    "    lines = ('lemma_ALL', 'count'),\n",
    "    tokens = ('lemma_ALL', 'sum'),\n",
    ").set_index(\n",
    "    line_labels['line_urn'].groupby(line_labels['sample_id']).agg('first')\n",
    ")\n",
    "display(sample_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63f47d",
   "metadata": {},
   "source": [
    "Whereas with no offset the first sample had 5 lines and the last one had 4, now the first has 1 and the last has 3. All the other samples still have 5 lines, but now they begin on, and are labelled by, different lines in the text.\n",
    "\n",
    "## Putting it all together\n",
    "\n",
    "If we run this process many times, then, changing `offset` each time, we can create samples of `size` lines that begin on every possible line in the corpus. If we then concatenate all these samples into one giant table, we'll have our overlapping sample set.\n",
    "\n",
    "In order to systematically perform all these steps many times while varying the parameters, it makes sense to rewrite them as a custom function. For each new offset, we can just call our function with a different argument. This is the **DRY** principle: \"Don't repeat yourself.\" Writing a custom function makes our workflow better in a couple of important ways:\n",
    "\n",
    "- we don't have to type the same stuff over and over again\n",
    "- we don't have to name or keep track of a lot of very similar tables\n",
    "- if (when) we make a mistake, we only have to correct it in one place\n",
    "\n",
    "Here's the full process for a given window size, offset, and features of interest. A couple of small things:\n",
    "\n",
    "- I'm adding the line labels directly to the feature table for simplicity.\n",
    "- I'm adding an option to drop samples that don't have the full complement of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838bd581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(size, offset, features, drop=False):\n",
    "    \n",
    "    # generate line labels\n",
    "    line_labels = pd.DataFrame(dict(\n",
    "        row = feat_count_line.index,\n",
    "        sample_id = (feat_count_line.index.codes - offset) // size * size + offset,\n",
    "    ))\n",
    "    \n",
    "    # generate sample labels\n",
    "    sample_labels = feat_count_line.groupby(line_labels.sample_id.values).agg(\n",
    "        lines = ('lemma_ALL', 'count'),\n",
    "        tokens = ('lemma_ALL', 'sum'),\n",
    "    )\n",
    "    \n",
    "    # generate samples\n",
    "    samples = (feat_count_line\n",
    "        .groupby(line_labels.sample_id.values)\n",
    "        .agg(\n",
    "            lines = ('lemma_ALL', 'count'),\n",
    "            tokens = ('lemma_ALL', 'sum'),\n",
    "        )\n",
    "        .join(\n",
    "            feat_count_line[features]\n",
    "                .groupby(line_labels.sample_id.values)\n",
    "                .agg('sum')\n",
    "        )\n",
    "        .set_index(\n",
    "            line_labels.row.groupby(line_labels.sample_id.values).agg('first')\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # optionally drop small samples\n",
    "    if drop:\n",
    "        samples = samples.loc[samples.lines == size]\n",
    "    \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588503a8",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "Let's try generating some features using different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ce611",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5\n",
    "offset = 0\n",
    "features = ['pos_ADJ', 'pos_ADV', 'person_2', 'person_3']\n",
    "\n",
    "get_samples(size, offset, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
